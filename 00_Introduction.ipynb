{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.nature.com/articles/s41598-020-60661-8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Jupyter Lab / Notebook\n",
    "\n",
    "- https://jupyter.org/\n",
    "- https://towardsdatascience.com/jupyter-notebooks-tips-and-tricks-4e995e7b1fd0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"1300\"\n",
       "            height=\"500\"\n",
       "            src=\"https://jupyter.org/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x267d8448548>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import IFrame    \n",
    "display(IFrame(\"https://jupyter.org/\", width=1300, height=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/img2.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shortcuts\n",
    "\n",
    "- Shift + Enter to run a cell (code or markdown).\n",
    "- A to insert a new cell above the current cell.\n",
    "- B to insert a new cell below the current cell.\n",
    "- M to change the current cell to Markdown\n",
    "- Y to change the current cell to code.\n",
    "- D + D (twice) to delete the selected cells.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Markdown\n",
    "\n",
    "https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet\n",
    "\n",
    "##### UL\n",
    "- abdc\n",
    "- erdf\n",
    "\n",
    "##### OL\n",
    "1. hi\n",
    "2. hello\n",
    "\n",
    "##### Blockquotes\n",
    "> Highlight cool stuff\n",
    "> or quotes\n",
    "\n",
    "##### Code\n",
    "```\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/sample_5000_clean.csv', index_col=\"Unnamed: 0\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "```\n",
    "\n",
    "##### Code (with syntax highlighting)\n",
    "###### Python\n",
    "```python\n",
    "import pandas as pd\n",
    "df = pd.read_csv('data/sample_5000_clean.csv', index_col=\"Unnamed: 0\")\n",
    "print(df.shape)\n",
    "df.head()\n",
    "```\n",
    "\n",
    "###### R\n",
    "```R\n",
    "tbl <- read.table(file.choose(),header=TRUE,sep=',')\n",
    "population <- tbl[c(\"NAME\",\"POPESTIMATE2009\",\"NPOPCHG_2009\")]\n",
    "smallest.state.pop <- min(population$POPESTIMATE2009)\n",
    "print(population[population$POPESTIMATE2009==smallest.state.pop,])\n",
    "```\n",
    "\n",
    "##### Tex\n",
    "$$  \\sum_{j=1}^{R} \\sum_{k=1}^{n_j} \\sum_{ l = \\max (k-q, 1), l \\neq k}^{\\min (k+q, d_j)} \\log (p(\\mathbf{v}_{l}^j|\\mathbf{v}_k^j)) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shell commands\n",
    "- !dir\n",
    "- !pip install [...]\n",
    "- ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\2020-01-17_nlp_seminar\n"
     ]
    }
   ],
   "source": [
    "!echo %cd%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Datentr„ger in Laufwerk D: ist Elements\n",
      " Volumeseriennummer: 882B-2E89\n",
      "\n",
      " Verzeichnis von D:\\2020-01-17_nlp_seminar\n",
      "\n",
      "07.03.2020  12:40    <DIR>          .\n",
      "07.03.2020  12:40    <DIR>          ..\n",
      "07.03.2020  12:27    <DIR>          .ipynb_checkpoints\n",
      "07.03.2020  12:40            34.954 00_Introduction.ipynb\n",
      "07.03.2020  12:27            20.117 01_data_prep.ipynb\n",
      "07.03.2020  11:56           163.967 02_Topic_Modelling.ipynb\n",
      "07.03.2020  12:01    <DIR>          data\n",
      "27.02.2020  18:49                84 drops.txt\n",
      "22.02.2020  19:18             3.392 get_data.ipynb\n",
      "07.03.2020  12:26    <DIR>          img\n",
      "15.02.2020  20:19           113.473 NLP_Seminar_2019-10-28.pdf\n",
      "22.02.2020  19:16    <DIR>          pvtm\n",
      "22.02.2020  19:17         1.118.381 reddit_comments.csv\n",
      "14.02.2020  16:06               304 setup_droplet.sh\n",
      "27.02.2020  18:50             6.179 setup_droplets.ipynb\n",
      "27.02.2020  14:20             3.233 sshd_config\n",
      "17.01.2020  22:02             3.355 sshd_config2\n",
      "27.02.2020  17:59             3.360 start_droplet.py\n",
      "              12 Datei(en),      1.470.799 Bytes\n",
      "               6 Verzeichnis(se), 1.161.774.759.936 Bytes frei\n"
     ]
    }
   ],
   "source": [
    "!dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\program files (x86)\\anaconda3\\envs\\py37\\lib\\site-packages (4.42.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Magic Commands\n",
    "- %time, %%time\n",
    "- %timeit, %%timeit\n",
    "- %whos\n",
    "- ... ([documentation](https://ipython.readthedocs.io/en/stable/interactive/magics.html), [more infos](https://towardsdatascience.com/the-top-5-magic-commands-for-jupyter-notebooks-2bf0c5ae4bb8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.95 ns ± 0.158 ns per loop (mean ± std. dev. of 7 runs, 100000000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit a=12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable   Type         Data/Info\n",
      "---------------------------------\n",
      "IFrame     type         <class 'IPython.lib.display.IFrame'>\n",
      "a          int          12\n",
      "df         DataFrame             Index           <...>\\n[5000 rows x 4 columns]\n",
      "pd         module       <module 'pandas' from 'C:<...>es\\\\pandas\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Help and Docstrings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mType:\u001b[0m        module\n",
       "\u001b[1;31mString form:\u001b[0m <module 'pandas' from 'C:\\\\Program Files (x86)\\\\Anaconda3\\\\envs\\\\py37\\\\lib\\\\site-packages\\\\pandas\\\\__init__.py'>\n",
       "\u001b[1;31mFile:\u001b[0m        c:\\program files (x86)\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\__init__.py\n",
       "\u001b[1;31mDocstring:\u001b[0m  \n",
       "pandas - a powerful data analysis and manipulation library for Python\n",
       "=====================================================================\n",
       "\n",
       "**pandas** is a Python package providing fast, flexible, and expressive data\n",
       "structures designed to make working with \"relational\" or \"labeled\" data both\n",
       "easy and intuitive. It aims to be the fundamental high-level building block for\n",
       "doing practical, **real world** data analysis in Python. Additionally, it has\n",
       "the broader goal of becoming **the most powerful and flexible open source data\n",
       "analysis / manipulation tool available in any language**. It is already well on\n",
       "its way toward this goal.\n",
       "\n",
       "Main Features\n",
       "-------------\n",
       "Here are just a few of the things that pandas does well:\n",
       "\n",
       "  - Easy handling of missing data in floating point as well as non-floating\n",
       "    point data.\n",
       "  - Size mutability: columns can be inserted and deleted from DataFrame and\n",
       "    higher dimensional objects\n",
       "  - Automatic and explicit data alignment: objects can be explicitly aligned\n",
       "    to a set of labels, or the user can simply ignore the labels and let\n",
       "    `Series`, `DataFrame`, etc. automatically align the data for you in\n",
       "    computations.\n",
       "  - Powerful, flexible group by functionality to perform split-apply-combine\n",
       "    operations on data sets, for both aggregating and transforming data.\n",
       "  - Make it easy to convert ragged, differently-indexed data in other Python\n",
       "    and NumPy data structures into DataFrame objects.\n",
       "  - Intelligent label-based slicing, fancy indexing, and subsetting of large\n",
       "    data sets.\n",
       "  - Intuitive merging and joining data sets.\n",
       "  - Flexible reshaping and pivoting of data sets.\n",
       "  - Hierarchical labeling of axes (possible to have multiple labels per tick).\n",
       "  - Robust IO tools for loading data from flat files (CSV and delimited),\n",
       "    Excel files, databases, and saving/loading data from the ultrafast HDF5\n",
       "    format.\n",
       "  - Time series-specific functionality: date range generation and frequency\n",
       "    conversion, moving window statistics, date shifting and lagging.\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[1;31mSignature:\u001b[0m\n",
       "\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0marg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'raise'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mdayfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0myearfirst\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mutc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mformat\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mexact\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0munit\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0minfer_datetime_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0morigin\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'unix'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m    \u001b[0mcache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
       "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
       "\u001b[1;31mDocstring:\u001b[0m\n",
       "Convert argument to datetime.\n",
       "\n",
       "Parameters\n",
       "----------\n",
       "arg : int, float, str, datetime, list, tuple, 1-d array, Series DataFrame/dict-like\n",
       "    The object to convert to a datetime.\n",
       "errors : {'ignore', 'raise', 'coerce'}, default 'raise'\n",
       "    - If 'raise', then invalid parsing will raise an exception.\n",
       "    - If 'coerce', then invalid parsing will be set as NaT.\n",
       "    - If 'ignore', then invalid parsing will return the input.\n",
       "dayfirst : bool, default False\n",
       "    Specify a date parse order if `arg` is str or its list-likes.\n",
       "    If True, parses dates with the day first, eg 10/11/12 is parsed as\n",
       "    2012-11-10.\n",
       "    Warning: dayfirst=True is not strict, but will prefer to parse\n",
       "    with day first (this is a known bug, based on dateutil behavior).\n",
       "yearfirst : bool, default False\n",
       "    Specify a date parse order if `arg` is str or its list-likes.\n",
       "\n",
       "    - If True parses dates with the year first, eg 10/11/12 is parsed as\n",
       "      2010-11-12.\n",
       "    - If both dayfirst and yearfirst are True, yearfirst is preceded (same\n",
       "      as dateutil).\n",
       "\n",
       "    Warning: yearfirst=True is not strict, but will prefer to parse\n",
       "    with year first (this is a known bug, based on dateutil behavior).\n",
       "utc : bool, default None\n",
       "    Return UTC DatetimeIndex if True (converting any tz-aware\n",
       "    datetime.datetime objects as well).\n",
       "format : str, default None\n",
       "    The strftime to parse time, eg \"%d/%m/%Y\", note that \"%f\" will parse\n",
       "    all the way up to nanoseconds.\n",
       "    See strftime documentation for more information on choices:\n",
       "    https://docs.python.org/3/library/datetime.html#strftime-and-strptime-behavior.\n",
       "exact : bool, True by default\n",
       "    Behaves as:\n",
       "    - If True, require an exact format match.\n",
       "    - If False, allow the format to match anywhere in the target string.\n",
       "\n",
       "unit : str, default 'ns'\n",
       "    The unit of the arg (D,s,ms,us,ns) denote the unit, which is an\n",
       "    integer or float number. This will be based off the origin.\n",
       "    Example, with unit='ms' and origin='unix' (the default), this\n",
       "    would calculate the number of milliseconds to the unix epoch start.\n",
       "infer_datetime_format : bool, default False\n",
       "    If True and no `format` is given, attempt to infer the format of the\n",
       "    datetime strings, and if it can be inferred, switch to a faster\n",
       "    method of parsing them. In some cases this can increase the parsing\n",
       "    speed by ~5-10x.\n",
       "origin : scalar, default 'unix'\n",
       "    Define the reference date. The numeric values would be parsed as number\n",
       "    of units (defined by `unit`) since this reference date.\n",
       "\n",
       "    - If 'unix' (or POSIX) time; origin is set to 1970-01-01.\n",
       "    - If 'julian', unit must be 'D', and origin is set to beginning of\n",
       "      Julian Calendar. Julian day number 0 is assigned to the day starting\n",
       "      at noon on January 1, 4713 BC.\n",
       "    - If Timestamp convertible, origin is set to Timestamp identified by\n",
       "      origin.\n",
       "cache : bool, default True\n",
       "    If True, use a cache of unique, converted dates to apply the datetime\n",
       "    conversion. May produce significant speed-up when parsing duplicate\n",
       "    date strings, especially ones with timezone offsets. The cache is only\n",
       "    used when there are at least 50 values. The presence of out-of-bounds\n",
       "    values will render the cache unusable and may slow down parsing.\n",
       "\n",
       "    .. versionadded:: 0.23.0\n",
       "\n",
       "    .. versionchanged:: 0.25.0\n",
       "        - changed default value from False to True.\n",
       "\n",
       "Returns\n",
       "-------\n",
       "datetime\n",
       "    If parsing succeeded.\n",
       "    Return type depends on input:\n",
       "\n",
       "    - list-like: DatetimeIndex\n",
       "    - Series: Series of datetime64 dtype\n",
       "    - scalar: Timestamp\n",
       "\n",
       "    In case when it is not possible to return designated types (e.g. when\n",
       "    any element of input is before Timestamp.min or after Timestamp.max)\n",
       "    return will have datetime.datetime type (or corresponding\n",
       "    array/Series).\n",
       "\n",
       "See Also\n",
       "--------\n",
       "DataFrame.astype : Cast argument to a specified dtype.\n",
       "to_timedelta : Convert argument to timedelta.\n",
       "convert_dtypes : Convert dtypes.\n",
       "\n",
       "Examples\n",
       "--------\n",
       "Assembling a datetime from multiple columns of a DataFrame. The keys can be\n",
       "common abbreviations like ['year', 'month', 'day', 'minute', 'second',\n",
       "'ms', 'us', 'ns']) or plurals of the same\n",
       "\n",
       ">>> df = pd.DataFrame({'year': [2015, 2016],\n",
       "...                    'month': [2, 3],\n",
       "...                    'day': [4, 5]})\n",
       ">>> pd.to_datetime(df)\n",
       "0   2015-02-04\n",
       "1   2016-03-05\n",
       "dtype: datetime64[ns]\n",
       "\n",
       "If a date does not meet the `timestamp limitations\n",
       "<https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
       "#timeseries-timestamp-limits>`_, passing errors='ignore'\n",
       "will return the original input instead of raising any exception.\n",
       "\n",
       "Passing errors='coerce' will force an out-of-bounds date to NaT,\n",
       "in addition to forcing non-dates (or non-parseable dates) to NaT.\n",
       "\n",
       ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='ignore')\n",
       "datetime.datetime(1300, 1, 1, 0, 0)\n",
       ">>> pd.to_datetime('13000101', format='%Y%m%d', errors='coerce')\n",
       "NaT\n",
       "\n",
       "Passing infer_datetime_format=True can often-times speedup a parsing\n",
       "if its not an ISO8601 format exactly, but in a regular format.\n",
       "\n",
       ">>> s = pd.Series(['3/11/2000', '3/12/2000', '3/13/2000'] * 1000)\n",
       ">>> s.head()\n",
       "0    3/11/2000\n",
       "1    3/12/2000\n",
       "2    3/13/2000\n",
       "3    3/11/2000\n",
       "4    3/12/2000\n",
       "dtype: object\n",
       "\n",
       ">>> %timeit pd.to_datetime(s, infer_datetime_format=True)  # doctest: +SKIP\n",
       "100 loops, best of 3: 10.4 ms per loop\n",
       "\n",
       ">>> %timeit pd.to_datetime(s, infer_datetime_format=False)  # doctest: +SKIP\n",
       "1 loop, best of 3: 471 ms per loop\n",
       "\n",
       "Using a unix epoch time\n",
       "\n",
       ">>> pd.to_datetime(1490195805, unit='s')\n",
       "Timestamp('2017-03-22 15:16:45')\n",
       ">>> pd.to_datetime(1490195805433502912, unit='ns')\n",
       "Timestamp('2017-03-22 15:16:45.433502912')\n",
       "\n",
       ".. warning:: For float arg, precision rounding might happen. To prevent\n",
       "    unexpected behavior use a fixed-width exact type.\n",
       "\n",
       "Using a non-unix epoch origin\n",
       "\n",
       ">>> pd.to_datetime([1, 2, 3], unit='D',\n",
       "...                origin=pd.Timestamp('1960-01-01'))\n",
       "DatetimeIndex(['1960-01-02', '1960-01-03', '1960-01-04'], dtype='datetime64[ns]', freq=None)\n",
       "\u001b[1;31mFile:\u001b[0m      c:\\program files (x86)\\anaconda3\\envs\\py37\\lib\\site-packages\\pandas\\core\\tools\\datetimes.py\n",
       "\u001b[1;31mType:\u001b[0m      function\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "?pd.to_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 1444\n",
      "-rwxrwxrwx 1 dl dl   27908 Mar  7 12:59 00_Introduction.ipynb\n",
      "-rwxrwxrwx 1 dl dl   20117 Mar  7 12:27 01_data_prep.ipynb\n",
      "-rwxrwxrwx 1 dl dl  163967 Mar  7 11:56 02_Topic_Modelling.ipynb\n",
      "-rwxrwxrwx 1 dl dl  113473 Feb 15 20:19 NLP_Seminar_2019-10-28.pdf\n",
      "drwxrwxrwx 1 dl dl    4096 Mar  7 12:01 data\n",
      "-rwxrwxrwx 1 dl dl      84 Feb 27 18:49 drops.txt\n",
      "-rwxrwxrwx 1 dl dl    3392 Feb 22 19:18 get_data.ipynb\n",
      "drwxrwxrwx 1 dl dl    4096 Mar  7 12:26 img\n",
      "drwxrwxrwx 1 dl dl    4096 Feb 22 19:16 pvtm\n",
      "-rwxrwxrwx 1 dl dl 1118381 Feb 22 19:17 reddit_comments.csv\n",
      "-rwxrwxrwx 1 dl dl     304 Feb 14 16:06 setup_droplet.sh\n",
      "-rwxrwxrwx 1 dl dl    6179 Feb 27 18:50 setup_droplets.ipynb\n",
      "-rwxrwxrwx 1 dl dl    3233 Feb 27 14:20 sshd_config\n",
      "-rwxrwxrwx 1 dl dl    3355 Jan 17 22:02 sshd_config2\n",
      "-rwxrwxrwx 1 dl dl    3360 Feb 27 17:59 start_droplet.py\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "\n",
    "ls -l "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dont use Jupyter Notebooks in Production\n",
    "\n",
    "- Export files to .py instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py37",
   "language": "python",
   "name": "py37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
